{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Stroop Test Analysis with Pandas\n",
    "\n",
    "Perform the same analysis as in Homework 3, on the same data.  While this is the same dataset, and the same analysis sequence, the different data organization (a data frame) will have a different \"feel\" to it than before.  As you work through the notebook, notice the differences and similarities in your code as when you were just working with 1D Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Paths\n",
    "The Data for this homework assignment is actually the same as the data from last week, except we'll be working directly from the original CSV File, which contains all of the data.  CSV Files are text files that store data in rows and columns.\n",
    "\n",
    "The Data File: 'Homework Sample Data/Homework 6'/'StroopData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CSV File into an Pandas DataFrame\n",
    "\n",
    "This is a lot of data! To display just the first 5 rows of the data (useful in these notebooks), use the **head()** method on the dataframe.  Note: The **Condition** column says whether the word displayed matches (Congruent) or doesn't match (Incongruent) its color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Many Trials were there in total across all subjects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Many Unique Subject IDs were there in this study?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the mean response time, across all subjects and conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram of the response times\n",
    "(Don't forget to make sure that **%matplotlib inline** has been run already in this notebook, or the plot may not show up!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "Make a \"Good Trials\" column, with False values for response times greater than 5000 msecs.  There is no way they should have taken that long!  Then, plot the RT histogram with only the good columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Response Times\n",
    "\n",
    "You should see that the responses are not normally distributed (if you can't see this, try using a higher number of **bins** in your histogram function).  While this isn't really a problem, it's very convenient when you have normally-distributed data.  Let's try transforming it to get something a bit nicer for statistical analysis...\n",
    "\n",
    "  - Make a new column with the **log** of the response times.  \n",
    "  - Plot a new histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reject Bad Data\n",
    "\n",
    "Now, that's a little nicer!  But wait... there's are some trials that seem to be on the low end, as well-- those with **log response times less than 5.7**.  After much consideration and deliberation with my supervisor, I've decided to remove those trials from my whole analysis, too! \n",
    "\n",
    "Make those too-slow trials also \"False\" in the \"Good Trials\" column, and plot the new, cleaner histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall, what was the accuracy of the responses? \n",
    "  - How many trials in total were correct (stimcolor matched respcolor), \n",
    "  - how many were incorrect, and \n",
    "  - what percent accuracy was there, overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matched vs Unmatched Colors: \n",
    "\n",
    "  - What was the mean log response time for Congruent trials (the stimulus word and color matched each other)?  \n",
    "  - What was the mean log response time for Incongruent trials (when they did not match)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Bar Graph of Log Response Time\n",
    "The bar graph should show Mean Log Response Times for the Congruent and Incongruent conditions, with Standard-Deviation Error Bars.  Put text labels on the x access showing which bars go with which condition.\n",
    "\n",
    "For help and an example, take a look at http://matplotlib.org/examples/api/barchart_demo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Bar Graph of Response Time\n",
    "\n",
    "The logged data doesn't make a very good impression of just how big an effect this is, sadly.  Let's make the same bar graph, but this time with the original response times, in milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change in Performance over Time\n",
    "\n",
    "In experiments like this, we assume that each trial is independent of each other.  Often, this isn't the case, and not taking that into account can sometimes lead to some wrong conclusions.  Let's see what we can find...\n",
    "\n",
    "### How did reaction time change over the course of a session? \n",
    "\n",
    "Were earlier trials faster or slower than later trials in a session, overall?  Make a scatter plot of the response times over the trial numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about between each subject?  Do all subjects show this difference in response time between the Congruent and Incogruent conditions, or is this just coming from a few subjects?\n",
    "(Hint: DataFrame.groupby() is useful for this kind of operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the difference in mean log reaction times between conditions for each subject!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think, should anyone be rejected?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant Response Speed vs. Size of Stroop Effect\n",
    "\n",
    "Make a scatter plot showing the relationship between how quickly subjects responded for congruent and incongruent stimuli!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an interesting effect, don't you think? Anyway, I think that's enough analysis.  Let's publish that last figure and move on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Figure to File\n",
    "\n",
    "Save the figure using **fig.savefig()** to your data directory as a png file!  Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
